{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'load_WRDS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mload_WRDS\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mload_assets\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'load_WRDS'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import load_WRDS\n",
    "import load_assets\n",
    "import config\n",
    "import Clean_data\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import yfinance as yf\n",
    "\n",
    "DATA_DIR = config.DATA_DIR\n",
    "OUTPUT_DIR = config.OUTPUT_DIR\n",
    "\n",
    "# Load the data from WRDS\n",
    "rcfd_series_1 = load_WRDS.load_RCFD_series_1(data_dir=DATA_DIR)\n",
    "rcon_series_1 = load_WRDS.load_RCON_series_1(data_dir=DATA_DIR)\n",
    "rcfd_series_2 = load_WRDS.load_RCFD_series_2(data_dir=DATA_DIR)\n",
    "rcon_series_2 = load_WRDS.load_RCON_series_2(data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load and clean the first dataset\n",
    "df13 = pd.read_excel('PerformanceGraphExport (1).xls')\n",
    "\n",
    "df13 = df13.drop_duplicates()\n",
    "df13 = df13.dropna(how='all')\n",
    "\n",
    "df13.columns = df13.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "num_cols = df13.select_dtypes(include='number').columns\n",
    "df13[num_cols] = df13[num_cols].fillna(0)\n",
    "\n",
    "obj_cols = df13.select_dtypes(include='object').columns\n",
    "df13[obj_cols] = df13[obj_cols].fillna('')\n",
    "\n",
    "df13 = df13.iloc[2:, :]\n",
    "\n",
    "df13.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df13.rename(columns={df13.columns[0]: \"date\"}, inplace=True)\n",
    "\n",
    "df13 = df13.iloc[:-1, :]\n",
    "\n",
    "df13.rename(columns={df13.columns[0]: \"date\", df13.columns[1]: \"sp 1-3\"}, inplace=True) \n",
    "\n",
    "start_date = pd.to_datetime(\"2019-03-08\")\n",
    "end_date = pd.to_datetime(\"2024-03-01\")\n",
    "\n",
    "df13 = df13[(df13['date'] >= start_date) & (df13['date'] <= end_date)]\n",
    "\n",
    "df13.reset_index(drop=True, inplace=True)\n",
    "\n",
    "##################################################################################\n",
    "#COMBINED SP35 CLEAN\n",
    "\n",
    "df35 = pd.read_excel('src/PerformanceGraphExport (2).xls')\n",
    "\n",
    "df35 = df35.drop_duplicates()\n",
    "df35 = df35.dropna(how='all')\n",
    "\n",
    "df35.columns = df35.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "num_cols = df35.select_dtypes(include='number').columns\n",
    "df35[num_cols] = df35[num_cols].fillna(0)\n",
    "\n",
    "obj_cols = df35.select_dtypes(include='object').columns\n",
    "df35[obj_cols] = df35[obj_cols].fillna('')\n",
    "\n",
    "df35 = df35.iloc[2:, :]\n",
    "\n",
    "df35.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df35.rename(columns={df35.columns[0]: \"date\"}, inplace=True)\n",
    "\n",
    "df35 = df35.iloc[:-1, :]\n",
    "\n",
    "df35.rename(columns={df35.columns[0]: \"date\", df35.columns[1]: \"sp 3-5\"}, inplace=True) \n",
    "\n",
    "start_date = pd.to_datetime(\"2019-03-08\")\n",
    "end_date = pd.to_datetime(\"2024-03-01\")\n",
    "\n",
    "df35 = df35[(df35['date'] >= start_date) & (df35['date'] <= end_date)]\n",
    "\n",
    "df35.reset_index(drop=True, inplace=True)\n",
    "\n",
    "###########################################################\n",
    "#COMBINED SP710 CLEAN\n",
    "\n",
    "df710 = pd.read_excel('PerformanceGraphExport (3).xls')\n",
    "\n",
    "df710 = df710.drop_duplicates()\n",
    "df710 = df710.dropna(how='all')\n",
    "\n",
    "df710.columns = df710.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "num_cols = df710.select_dtypes(include='number').columns\n",
    "df710[num_cols] = df710[num_cols].fillna(0)\n",
    "\n",
    "obj_cols = df710.select_dtypes(include='object').columns\n",
    "df710[obj_cols] = df710[obj_cols].fillna('')\n",
    "\n",
    "df710 = df710.iloc[2:, :]\n",
    "\n",
    "df710.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df710.rename(columns={df710.columns[0]: \"date\"}, inplace=True)\n",
    "\n",
    "df710 = df710.iloc[:-1, :]\n",
    "\n",
    "df710.rename(columns={df710.columns[0]: \"date\", df710.columns[1]: \"sp 7-10\"}, inplace=True) \n",
    "\n",
    "start_date = pd.to_datetime(\"2019-03-08\")\n",
    "end_date = pd.to_datetime(\"2024-03-01\")\n",
    "\n",
    "df710 = df710[(df710['date'] >= start_date) & (df710['date'] <= end_date)]\n",
    "\n",
    "df710.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df13)\n",
    "print(df35)\n",
    "print(df710)\n",
    "\n",
    "###############################################################################################\n",
    "#YFINANCE iShares\n",
    "tickers = {\n",
    "    \"iShares 0-1\": \"IB01.L\",   # iShares Short Treasury Bond ETF\n",
    "    \"iShares 1-3\": \"SHY\",   # iShares 1-3 Year Treasury Bond ETF\n",
    "    \"iShares 7-10\": \"IEF\",  # iShares 7-10 Year Treasury Bond ETF\n",
    "    \"iShares 10-20\": \"TLH\", # iShares 10-20 Year Treasury Bond ETF\n",
    "    \"iShares 20+\": \"TLT\"    # iShares 20+ Year Treasury Bond ETF\n",
    "}\n",
    "\n",
    "# Define date range\n",
    "start_date = \"2019-03-08\"\n",
    "end_date = \"2024-03-01\"\n",
    "\n",
    "# Fetch data\n",
    "iShares = yf.download(list(tickers.values()), start=start_date, end=end_date, progress=False)[\"Close\"]\n",
    "\n",
    "# Rename columns to match requested format\n",
    "iShares.columns = list(tickers.keys())\n",
    "\n",
    "# Reset index and rename date column\n",
    "iShares.reset_index(inplace=True)\n",
    "iShares.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "#JOINING ISHARES AND COMBINED PT 1,2,3\n",
    "\n",
    "# Convert the 'date' column in all DataFrames to datetime format\n",
    "dfs = [iShares, df13, df35, df710]\n",
    "for df in dfs:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Merge all DataFrames on the 'date' column using an outer join\n",
    "treasury_prices = iShares.merge(df13, on='date', how='outer') \\\n",
    "                   .merge(df35, on='date', how='outer') \\\n",
    "                   .merge(df710, on='date', how='outer')\n",
    "\n",
    "treasury_prices = treasury_prices.set_index(\"date\").asfreq(\"D\").ffill()\n",
    "treasury_prices = treasury_prices.reset_index()\n",
    "\n",
    "treasury_prices_1 = treasury_prices.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct the calculations\n",
    "\n",
    "###################################################################################\n",
    "#YFINANCE MBS automation\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Define the ticker symbol\n",
    "ticker_symbol = \"MBB\"\n",
    "\n",
    "# Set the date range based on your dataset\n",
    "start_date = \"2019-03-11\"\n",
    "end_date = \"2024-03-08\"\n",
    "\n",
    "# Fetch historical market data for MBB within the same date range\n",
    "df_iShare_MBS_ETF = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
    "df_iShare_MBS_ETF.columns = df_iShare_MBS_ETF.columns.get_level_values(0)\n",
    "df_iShare_MBS_ETF.rename(columns={\"Close\": \"Adj Close\"}, inplace=True)\n",
    "df_iShare_MBS_ETF = df_iShare_MBS_ETF.reset_index()\n",
    "df_iShare_MBS_ETF_1 = df_iShare_MBS_ETF.copy()\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "# Load the data from the manual\n",
    "def RMBs_Multiplier(df_SP_Treasury_bond_index, df_iShare_MBS_ETF, start_date = '2022-03-31', end_date = '2023-03-31'):\n",
    "    \"\"\"\n",
    "    Calculate the multiplier for the MBS assets based on the change in the S&P U.S. Treasury Bond Index and iShares MBS ETF.\n",
    "\n",
    "    Parameters:\n",
    "    df_SP_Treasury_bond_index (pd.DataFrame): DataFrame containing the S&P U.S. Treasury Bond Index data.\n",
    "    df_iShare_MBS_ETF (pd.DataFrame): DataFrame containing the iShares MBS ETF data.\n",
    "    start_date (str): Start date for the calculation (default is '2022-03-31').\n",
    "\n",
    "    Returns:\n",
    "    float: The multiplier for the MBS assets based on the change in the S&P U.S. Treasury Bond Index and iShares MBS ETF.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    upper_treasury = df_SP_Treasury_bond_index.loc[end_date, 'S&P U.S. Treasury Bond Index']\n",
    "    lower_treasury = df_SP_Treasury_bond_index.loc[start_date, 'S&P U.S. Treasury Bond Index']\n",
    "    \n",
    "    upper_MBS = df_iShare_MBS_ETF.loc[end_date, 'Adj Close']\n",
    "    lower_MBS = df_iShare_MBS_ETF.loc[start_date, 'Adj Close']\n",
    "    \n",
    "    MBS_change = (upper_MBS / lower_MBS) - 1\n",
    "    treasury_change = (upper_treasury / lower_treasury) - 1\n",
    "    multiplier = MBS_change / treasury_change\n",
    "    \n",
    "    return multiplier\n",
    "\n",
    "def report_losses(df_RMBS_Final, df_loans_first_lien_domestic, df_treasury_and_others, df_other_loan, treasury_prices, RMBS_multiplier, df_asset, start_date = '2022-03-31', end_date = '2023-03-31'):      \n",
    "    \"\"\"\n",
    "    Calculate the losses for each asset type based on the change in the market indices.\n",
    "\n",
    "    Parameters:\n",
    "    df_RMBS_Final (pd.DataFrame): DataFrame containing the RMBS assets data.\n",
    "    df_loans_first_lien_domestic (pd.DataFrame): DataFrame containing the loans data.\n",
    "    df_treasury_and_others (pd.DataFrame): DataFrame containing the treasury and other assets data.\n",
    "    df_other_loan (pd.DataFrame): DataFrame containing the other loan assets data.\n",
    "    treasury_prices (pd.DataFrame): DataFrame containing the treasury prices data.\n",
    "    RMBS_multiplier (float): The multiplier for the MBS assets based on the change in the S&P U.S. Treasury Bond Index and iShares MBS ETF.\n",
    "    df_asset (pd.DataFrame): DataFrame containing the total assets data.\n",
    "    start_date (str): Start date for the calculation (default is '2022-03-31').\n",
    "    end_date (str): End date for the calculation (default is '2023-03-31').\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the losses and assets for each bank.\n",
    "    \"\"\"  \n",
    "    # Insert the price changes for each treasury bond\n",
    "    price_change = {\n",
    "        '<1y': -0.02,\n",
    "        '1y-3y': -0.06,\n",
    "        '3y-5y': -0.10,\n",
    "        '7y-10y': -0.20,\n",
    "        '>20y': -0.30\n",
    "    }\n",
    "\n",
    "    # Define the mapping of buckets to be used for aggregation\n",
    "    bucket_mapping = {\n",
    "        '<3m': '<1y',\n",
    "        '3m-1y': '<1y',\n",
    "        '1y-3y': '1y-3y',\n",
    "        '3y-5y': '3y-5y',\n",
    "        '5y-15y': '7y-10y',  # Assuming '5y-15y' should be mapped to '7y-10y' based on provided price_change calculation\n",
    "        '>15y': '>20y',\n",
    "    }\n",
    "      \n",
    "    # Aggregate the assets for each bank\n",
    "    aggregated_assets = {}\n",
    "    for name, df in zip(['RMBS', 'Loans', 'Treasury', 'OtherLoan'], \n",
    "                        [df_RMBS_Final, df_loans_first_lien_domestic, df_treasury_and_others, df_other_loan]):\n",
    "        # Ensure columns for aggregation are present\n",
    "        columns_to_aggregate = [col for col in list(bucket_mapping.keys()) if col in df.columns]\n",
    "        aggregated_assets[name] = df.groupby(['bank_name', 'Bank_ID'])[columns_to_aggregate].sum().reset_index()\n",
    "    \n",
    "    # Initialize DataFrame to store results\n",
    "    bank_losses_assets = pd.DataFrame(columns=[\n",
    "        'bank_name', 'bank_ID', 'RMBs_loss', 'treasury_loss', 'loans_loss', 'other_loan_loss', \n",
    "        'total_loss', 'Share RMBs', 'Share Treasury and Other', \n",
    "        'Share Residential Mortgage', 'Share Other Loan', 'RMBs_asset', 'treasury_asset', \n",
    "        'residential_mortgage_asset', 'other_loan_asset', 'core_asset', 'gross_asset', 'loss/core_asset', 'loss/gross_asset',\n",
    "    ])\n",
    "    \n",
    "    # Iterate over each bank to calculate losses and assets\n",
    "    for _, df_row in df_asset.iterrows():\n",
    "        bank = df_row['bank_name']\n",
    "        bank_id = df_row['Bank_ID']\n",
    "        bank_total_asset = df_row['gross_asset']\n",
    "        \n",
    "        #Initialize variables for loss and asset calculations\n",
    "        rmbs_loss = loans_loss = treasury_loss = other_loan_loss = total_loss = 0\n",
    "        rmbs_asset = treasury_asset = loan_asset = other_loan_asset = core_asset = 0\n",
    "        \n",
    "        #Calculating losses for RMBs\n",
    "        if 'RMBS' in aggregated_assets and not aggregated_assets['RMBS'].empty:\n",
    "            rmbs_row = aggregated_assets['RMBS'][(aggregated_assets['RMBS']['bank_name'] == bank) & (aggregated_assets['RMBS']['Bank_ID'] == bank_id)]\n",
    "            for bucket, treasury_bucket in bucket_mapping.items():\n",
    "                if bucket in rmbs_row.columns:\n",
    "                    asset_amount = rmbs_row.iloc[0][bucket] if not rmbs_row.empty else 0\n",
    "                    rmbs_loss += (asset_amount * RMBS_multiplier * price_change[treasury_bucket])\n",
    "                    rmbs_asset += asset_amount\n",
    "                    \n",
    "        #Calculating losses for loans\n",
    "        loans_row = aggregated_assets['Loans'][(aggregated_assets['Loans']['bank_name'] == bank) & (aggregated_assets['Loans']['Bank_ID'] == bank_id)]\n",
    "        if not loans_row.empty:\n",
    "            for bucket, treasury_bucket in bucket_mapping.items():\n",
    "                if bucket in loans_row.columns:\n",
    "                    asset_amount = loans_row.iloc[0][bucket]\n",
    "                    loans_loss += (asset_amount * RMBS_multiplier * price_change[treasury_bucket])\n",
    "                    loan_asset += asset_amount\n",
    "\n",
    "        #Calculating Treasuries\n",
    "        treasury_row = aggregated_assets['Treasury'][(aggregated_assets['Treasury']['bank_name'] == bank) & (aggregated_assets['Treasury']['Bank_ID'] == bank_id)]\n",
    "        if not treasury_row.empty:\n",
    "            for bucket, treasury_bucket in bucket_mapping.items():\n",
    "                if bucket in treasury_row.columns:\n",
    "                    asset_amount = treasury_row.iloc[0][bucket]\n",
    "                    treasury_loss += (asset_amount * price_change[treasury_bucket])\n",
    "                    treasury_asset += asset_amount\n",
    "\n",
    "        #Other loans\n",
    "        other_loan_row = aggregated_assets['OtherLoan'][(aggregated_assets['OtherLoan']['bank_name'] == bank) & (aggregated_assets['OtherLoan']['Bank_ID'] == bank_id)]\n",
    "        if not other_loan_row.empty:\n",
    "            for bucket, treasury_bucket in bucket_mapping.items():\n",
    "                if bucket in other_loan_row.columns:\n",
    "                    asset_amount = other_loan_row.iloc[0][bucket]\n",
    "                    other_loan_loss += (asset_amount * price_change[treasury_bucket])\n",
    "                    other_loan_asset += asset_amount\n",
    "\n",
    "        # Calculate total loss and core asset      \n",
    "        total_loss = rmbs_loss + treasury_loss + loans_loss + other_loan_loss\n",
    "        core_asset = rmbs_asset + treasury_asset + loan_asset + other_loan_asset\n",
    "\n",
    "        # Append the results to the DataFrame\n",
    "        bank_losses_assets.loc[len(bank_losses_assets)] = {\n",
    "            'bank_name': bank,\n",
    "            'bank_ID': bank_id,\n",
    "            'RMBs_loss': rmbs_loss,\n",
    "            'treasury_loss': treasury_loss,\n",
    "            'loans_loss': loans_loss,\n",
    "            'other_loan_loss': other_loan_loss,\n",
    "            'total_loss': total_loss,\n",
    "            'Share RMBs': rmbs_loss / total_loss if total_loss else 0,\n",
    "            'Share Treasury and Other': treasury_loss / total_loss if total_loss else 0,\n",
    "            'Share Residential Mortgage': loans_loss / total_loss if total_loss else 0,\n",
    "            'Share Other Loan': other_loan_loss / total_loss if total_loss else 0,\n",
    "            'RMBs_asset': rmbs_asset,\n",
    "            'treasury_asset': treasury_asset,\n",
    "            'residential_mortgage_asset': loan_asset,\n",
    "            'other_loan_asset': other_loan_asset,\n",
    "            'core_asset': core_asset,\n",
    "            'gross_asset': bank_total_asset,\n",
    "            'loss/core_asset': -(total_loss / core_asset) if core_asset else 0,\n",
    "            'loss/gross_asset': -(total_loss / bank_total_asset) if bank_total_asset else 0,\n",
    "        }\n",
    "\n",
    "    return bank_losses_assets\n",
    "\n",
    "def calculate_uninsured_deposit_mm_asset(uninsured_deposit, bank_losses_assets):\n",
    "    \"\"\"\n",
    "    Calculate the uninsured deposit/MM asset ratio for each bank.\n",
    "\n",
    "    Parameters:\n",
    "    uninsured_deposit (pd.DataFrame): DataFrame containing the uninsured deposit data.\n",
    "    bank_losses_assets (pd.DataFrame): DataFrame containing the losses and assets for each bank.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the uninsured deposit/MM asset ratio for each bank.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "    \n",
    "    # Adjust the uninsured_deposit DataFrame to use both 'bank_name' and 'Bank_ID' as a multi-index for quick lookup\n",
    "    uninsured_lookup = uninsured_deposit.set_index(['bank_name', 'bank_ID'])['uninsured_deposit'].to_dict()\n",
    "    \n",
    "    # Iterate over each row in bank_losses DataFrame\n",
    "    for _, bank_loss_row in bank_losses_assets.iterrows():\n",
    "        bank_name = bank_loss_row['bank_name']\n",
    "        bank_id = bank_loss_row['bank_ID']\n",
    "        \n",
    "        # Adjust the lookup to include 'Bank_ID'\n",
    "        uninsured_deposit_value = uninsured_lookup.get((bank_name, bank_id), 0)\n",
    "        \n",
    "        # Calculate 'MM Asset' as (as defined in the paper)\n",
    "        mm_asset = bank_loss_row['total_loss'] + bank_loss_row['gross_asset']\n",
    "        \n",
    "        # Calculate Uninsured Deposit/MM Asset ratio \n",
    "        if mm_asset > 0:\n",
    "            uninsured_deposit_mm_asset_ratio = uninsured_deposit_value / mm_asset\n",
    "        \n",
    "        # Append to final dataframe\n",
    "        results.append({\n",
    "            'bank_name': bank_name,\n",
    "            'bank_ID': bank_id, \n",
    "            'total_loss': bank_loss_row['total_loss'], \n",
    "            'total_asset': bank_loss_row['gross_asset'],\n",
    "            'mm_asset': mm_asset,\n",
    "            'uninsured_deposit': uninsured_deposit_value, \n",
    "            'Uninsured_Deposit_MM_Asset': uninsured_deposit_mm_asset_ratio\n",
    "        })\n",
    "\n",
    "    # Convert results list to DataFrame and sort by 'Bank_ID'\n",
    "    uninsured_deposit_mm_asset = pd.DataFrame(results).sort_values(by=['bank_name', 'bank_ID'])\n",
    "    \n",
    "    return uninsured_deposit_mm_asset\n",
    "\n",
    "def insured_deposit_coverage_ratio(insured_deposit, uninsured_deposit, bank_losses):\n",
    "    \"\"\"\n",
    "    Calculate the insured deposit coverage ratio for each bank.\n",
    "\n",
    "    Parameters:\n",
    "    insured_deposit (pd.DataFrame): DataFrame containing the insured deposit data.\n",
    "    uninsured_deposit (pd.DataFrame): DataFrame containing the uninsured deposit data.\n",
    "    bank_losses (pd.DataFrame): DataFrame containing the losses and assets for each bank.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the insured deposit coverage ratio for each bank.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the results\n",
    "    results = []\n",
    "    \n",
    "    # Create dictionaries from insured and uninsured deposits for quick lookup\n",
    "    insured_lookup = insured_deposit.set_index(['bank_name', 'bank_ID'])['insured_deposit'].to_dict()\n",
    "    uninsured_lookup = uninsured_deposit.set_index(['bank_name', 'bank_ID'])['uninsured_deposit'].to_dict()\n",
    "    \n",
    "    # Iterate over each row in bank_losses DataFrame\n",
    "    for _, bank_loss_row in bank_losses.iterrows():\n",
    "        bank_name = bank_loss_row['bank_name']\n",
    "        bank_id = bank_loss_row['bank_ID']\n",
    "        \n",
    "        # Retrieve insured and uninsured deposit values\n",
    "        insured_deposit_value = insured_lookup.get((bank_name, bank_id), 0)\n",
    "        uninsured_deposit_value = uninsured_lookup.get((bank_name, bank_id), 0)\n",
    "        \n",
    "        # Calculate mark-to-market asset value \n",
    "        mark_to_market_asset_value = bank_loss_row['total_loss'] + bank_loss_row['gross_asset']\n",
    "        \n",
    "        # Calculate the insured deposit coverage ratio\n",
    "        if insured_deposit_value > 0:  # Prevent division by zero\n",
    "            coverage_ratio = (mark_to_market_asset_value - uninsured_deposit_value - insured_deposit_value) / insured_deposit_value\n",
    "        \n",
    "        # Append the result\n",
    "        results.append({\n",
    "            'bank_name': bank_name,\n",
    "            'bank_ID': bank_id,\n",
    "            'mm_asset': mark_to_market_asset_value,\n",
    "            'insured_deposit': insured_deposit_value,\n",
    "            'uninsured_deposit': uninsured_deposit_value,\n",
    "            'insured_deposit_coverage_ratio': coverage_ratio\n",
    "        })\n",
    "    \n",
    "    # Convert results list to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def final_statistic_table(bank_losses_assets, uninsured_deposit_mm_asset, insured_deposit_coverage, index_name = 'All Banks'):\n",
    "    \"\"\"\n",
    "    Calculate the final statistics table for the banks.\n",
    "\n",
    "    Parameters:\n",
    "    bank_losses_assets (pd.DataFrame): DataFrame containing the losses and assets for each bank.\n",
    "    uninsured_deposit_mm_asset (pd.DataFrame): DataFrame containing the uninsured deposit/MM asset ratio for each bank.\n",
    "    insured_deposit_coverage (pd.DataFrame): DataFrame containing the insured deposit coverage ratio for each bank.\n",
    "    index_name (str): Name of the index (default is 'All Banks').\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame containing the final statistics table.\n",
    "    \"\"\"\n",
    "    \n",
    "    bank_count = len(bank_losses_assets.index)\n",
    "\n",
    "    final_stats = pd.DataFrame({\n",
    "        'Aggregate Loss': [f\"{-round(bank_losses_assets['total_loss'].sum() / 1e9, 1)}T\"],  # Convert to trillions\n",
    "        'Bank Level Loss': [f\"{-round(bank_losses_assets['total_loss'].median() / 1e3, 1)}M\"],  # Convert to millions\n",
    "        'Bank Level Loss Std': [f\"{round(bank_losses_assets['total_loss'].std() / 1e6, 2)}B\"],  # Std deviation for Bank Level Loss\n",
    "        'Share RMBS': [round(bank_losses_assets['Share RMBs'].median() * 100, 1)],  # Median percentage\n",
    "        'Share RMBS Std': [round(bank_losses_assets['Share RMBs'].std() * 100, 1)],  # Std deviation for Share RMBS\n",
    "        'Share Treasury and Other': [round(bank_losses_assets['Share Treasury and Other'].median() * 100, 1)],  # Median percentage\n",
    "        'Share Treasury and Other Std': [round(bank_losses_assets['Share Treasury and Other'].std() * 100, 1)],  # Std deviation\n",
    "        'Share Residential Mortgage': [round(bank_losses_assets['Share Residential Mortgage'].median() * 100, 1)],  # Median percentage\n",
    "        'Share Residential Mortgage Std': [round(bank_losses_assets['Share Residential Mortgage'].std() * 100, 1)],  # Std deviation\n",
    "        'Share Other Loan': [round(bank_losses_assets['Share Other Loan'].median() * 100, 1)],  # Median percentage\n",
    "        'Share Other Loan Std': [round(bank_losses_assets['Share Other Loan'].std() * 100, 1)],  # Std deviation\n",
    "        'Loss/Asset': [round(bank_losses_assets['loss/gross_asset'].median() * 100, 1)],  # Median percentage\n",
    "        'Loss/Asset Std': [round(bank_losses_assets['loss/gross_asset'].std() * 100, 1)],  # Std deviation\n",
    "        'Uninsured Deposit/MM Asset': [round(uninsured_deposit_mm_asset['Uninsured_Deposit_MM_Asset'].median() * 100, 1)],  # Median percentage\n",
    "        'Uninsured Deposit/MM Asset Std': [round(uninsured_deposit_mm_asset['Uninsured_Deposit_MM_Asset'].std() * 100, 1)],  # Std deviation\n",
    "        'Insured Deposit Coverage Ratio': [round(insured_deposit_coverage['insured_deposit_coverage_ratio'].median() * 100, 1)],  # Median percentage\n",
    "        'Insured Deposit Coverage Ratio Std': [round(insured_deposit_coverage['insured_deposit_coverage_ratio'].std() * 100, 1)],  # Std deviation\n",
    "        'Number of Banks': [len(bank_losses_assets.index.unique())]  # Count of unique banks\n",
    "    })\n",
    "\n",
    "    # Rename index to 'All Banks'\n",
    "    final_stats.index = [index_name]\n",
    "\n",
    "    final_stats = final_stats.T # Transpose the DataFrame\n",
    "    \n",
    "    return final_stats\n",
    "\n",
    "def GSIB_bank_id():\n",
    "    \"\"\"\n",
    "    Returns a list of GSIB bank IDs.\n",
    "    \"\"\"\n",
    "    #GSIB = [35301,93619,229913,398668,413208,451965,476810,480228,488318,\n",
    "     #497404,541101,651448,688079,722777,812164,852218,934329,1225761,\n",
    "     #1443266,1456501,2182786,2362458,2489805,2531991,3066025]\n",
    "    GSIB = [852218, 480228, 476810, 413208, #JP Morgan, Bank of America, Citigroup, HSBC\n",
    "      2980209, 2182786, 541101, 655839, 1015560, 229913,#Barclays, Goldman Sachs, BNY Mellon, CCB COMMUNITY BANK, ICBC, Mizuho\n",
    "       1456501, 722777, 35301, 925411, 497404, 3212149, #Morgan Stanley, Santander, State Street, Sumitomo Mitsui, TD Bank, UBS\n",
    "      451965] #wells fargo\n",
    "    return GSIB\n",
    "\n",
    "def large_ex_GSIB_bank_id(large):\n",
    "    \"\"\"\n",
    "    Returns a list of large non-GSIB bank IDs.\n",
    "    \"\"\"\n",
    "    bank_id_large_ex_GSIB = []\n",
    "    for bank_id in large['Bank_ID']:\n",
    "       bank_id_large_ex_GSIB.append(bank_id)\n",
    "    return bank_id_large_ex_GSIB\n",
    "\n",
    "def small_bank_id(small):\n",
    "    \"\"\"\n",
    "    Returns a list of small bank IDs.\n",
    "    \"\"\"\n",
    "    bank_id_small = []\n",
    "    for bank_id in small['Bank_ID']:\n",
    "       bank_id_small.append(bank_id)\n",
    "    return bank_id_small\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ##Clean the dataframes for table 1##################################################################################################################################### \n",
    "    treasury_prices = Clean_data.clean_treasury_prices(treasury_prices, start_date = '2022-03-31', end_date = '2023-03-31')\n",
    "    df_SP_Treasury_bond_index = Clean_data.clean_sp_treasury_bond_index(df_SP_Treasury_bond_index, start_date = '2022-03-31', end_date = '2023-03-31')\n",
    "    df_iShare_MBS_ETF = Clean_data.clean_iShare_MBS_ETF(df_iShare_MBS_ETF, start_date = '2022-03-31', end_date = '2023-03-31')\n",
    "    RMBS_multiplier = RMBs_Multiplier(df_SP_Treasury_bond_index, df_iShare_MBS_ETF, start_date = '2022-03-31', end_date = '2023-03-31') #MBS multiplier\n",
    "\n",
    "    ##Prepare the dataframes for table 2 (with most up-to-date market indices data)##################################################################################################################################### \n",
    "    treasury_prices_updated = Clean_data.clean_treasury_prices(treasury_prices_1, start_date = '2022-03-31', end_date = '2023-12-31')\n",
    "    df_SP_Treasury_bond_index_updated = Clean_data.clean_sp_treasury_bond_index(df_SP_Treasury_bond_index_1, start_date = '2022-03-31', end_date = '2023-12-31')\n",
    "    df_iShare_MBS_ETF_updated = Clean_data.clean_iShare_MBS_ETF(df_iShare_MBS_ETF_1, start_date = '2022-03-31', end_date = '2023-12-31')\n",
    "    RMBS_multiplier_updated = RMBs_Multiplier(df_SP_Treasury_bond_index_updated, df_iShare_MBS_ETF_updated, start_date = '2022-03-31', end_date = '2023-12-31') #MBS multiplier\n",
    "    \n",
    "    ##Get the required dataframes##################################################################################################################################### \n",
    "    df_RMBS_Final = Clean_data.get_RMBs(rcfd_series_1, rcon_series_1)\n",
    "    df_loans_first_lien_domestic = Clean_data.get_loans(rcon_series_1)\n",
    "    df_treasury_and_others = Clean_data.get_treasuries(rcfd_series_2, rcon_series_2)\n",
    "    df_other_loan = Clean_data.get_other_loan(rcon_series_2, rcfd_series_1)\n",
    "    df_asset = Clean_data.get_total_asset(rcfd_series_2, rcon_series_2)\n",
    "    uninsured_deposit = Clean_data.get_uninsured_deposits(rcon_series_1)\n",
    "    insured_deposits = Clean_data.get_insured_deposits(rcon_series_1)\n",
    "\n",
    "    ##Sort the dataframes#####################################################################################################################################\n",
    "    df_asset = df_asset #total assets all banks\n",
    "    #GSIB Banks\n",
    "    GSIB = GSIB_bank_id() #list of GSIB bank IDs\n",
    "    df_asset_GSIB = df_asset[df_asset['Bank_ID'].isin(GSIB)] #total assets all GSIB banks\n",
    "    #Large non-GSIB Banks\n",
    "    df_asset_large_ex_GSIB = df_asset[(~df_asset['Bank_ID'].isin(GSIB)) & (df_asset['gross_asset']>1384000)] #total assets all large non-GSIB banks\n",
    "    large_ex_GSIB = large_ex_GSIB_bank_id(df_asset_large_ex_GSIB) #list of large non-GSIB bank IDs\n",
    "    #Small Banks\n",
    "    df_asset_small = df_asset[(~df_asset['Bank_ID'].isin(GSIB)) & (df_asset['gross_asset']<=1384000)] #total asset all small banks \n",
    "    small = small_bank_id(df_asset_small) #list of small bank IDs\n",
    "\n",
    "    ##Prepare each asset type###################################################################################################################################\n",
    "    #RMBS\n",
    "    df_RMBS_Final = df_RMBS_Final #RMBS for all banks \n",
    "    df_RMBS_GSIB = df_RMBS_Final[df_RMBS_Final['Bank_ID'].isin(GSIB)] #RMBS for GSIB banks\n",
    "    df_RMBS_large_ex_GSIB = df_RMBS_Final[df_RMBS_Final['Bank_ID'].isin(large_ex_GSIB)] #RMBS for large non-GSIB banks\n",
    "    df_RMBS_small = df_RMBS_Final[df_RMBS_Final['Bank_ID'].isin(small)] #RMBS for small banks\n",
    "\n",
    "    #Loans First Lien Domestic\n",
    "\n",
    "    df_loans_first_lien_domestic = df_loans_first_lien_domestic # loans first lien domestic for all banks\n",
    "    df_loans_first_lien_domestic_GSIB = df_loans_first_lien_domestic[df_loans_first_lien_domestic['Bank_ID'].isin(GSIB)] # loans first lien domestic for all GSIB banks\n",
    "    df_loans_first_lien_domestic_large_ex_GSIB = df_loans_first_lien_domestic[df_loans_first_lien_domestic['Bank_ID'].isin(large_ex_GSIB)] # loans first lien domestic for all large non-GSIB banks\n",
    "    df_loans_first_lien_domestic_small = df_loans_first_lien_domestic[df_loans_first_lien_domestic['Bank_ID'].isin(small)]\n",
    "\n",
    "    #Treasury and Others\n",
    "\n",
    "    df_treasury_and_others = df_treasury_and_others #treasury and others all banks \n",
    "    df_treasury_and_others_GSIB = df_treasury_and_others[df_treasury_and_others['Bank_ID'].isin(GSIB)] #treasury and others GSIB banks\n",
    "    df_treasury_and_others_large_ex_GSIB = df_treasury_and_others[df_treasury_and_others['Bank_ID'].isin(large_ex_GSIB)] #treasury and others large non-GSIB baanks \n",
    "    df_treasury_and_others_small = df_treasury_and_others[df_treasury_and_others['Bank_ID'].isin(small)] #treasury and others small banks \n",
    "    \n",
    "    #Other Loan \n",
    "\n",
    "    df_other_loan = df_other_loan #other loans for all banks \n",
    "    df_other_loan_GSIB = df_other_loan[df_other_loan['Bank_ID'].isin(GSIB)] #other loans for all GSIB banks \n",
    "    df_other_loan_large_ex_GSIB = df_other_loan[df_other_loan['Bank_ID'].isin(large_ex_GSIB)] #other loans for all large non-GSIB banks\n",
    "    df_other_loan_small = df_other_loan[df_other_loan['Bank_ID'].isin(small)] #other oans for all small banks \n",
    "\n",
    "    #uninsured deposits\n",
    "    uninsured_deposit = uninsured_deposit #uninsured deposits for all banks\n",
    "    uninsured_deposit_GSIB = uninsured_deposit[uninsured_deposit['bank_ID'].isin(GSIB)] #uninsured deposits for GSIB banks\n",
    "    uninsured_deposit_large_ex_GSIB = uninsured_deposit[uninsured_deposit['bank_ID'].isin(large_ex_GSIB)] #uninsured deposits for large non-GSIB banks\n",
    "    uninsured_deposit_small = uninsured_deposit[uninsured_deposit['bank_ID'].isin(small)] #uninsured deposits for small banks\n",
    "\n",
    "    #insured deposits\n",
    "    insured_deposits = insured_deposits #insured deposits for all banks\n",
    "    insured_deposits_GSIB = insured_deposits[insured_deposits['bank_ID'].isin(GSIB)] #insured deposits for GSIB banks\n",
    "    insured_deposits_large_ex_GSIB = insured_deposits[insured_deposits['bank_ID'].isin(large_ex_GSIB)] #insured deposits for large non-GSIB banks\n",
    "    insured_deposits_small = insured_deposits[insured_deposits['bank_ID'].isin(small)] #insured deposits for small banks\n",
    "\n",
    "    \"\"\"\n",
    "    The following code runs the statistics for table 1 (as in the paper)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    ##Calculations for all banks##################################################################################################################################### \n",
    "    # Calculate the losses \n",
    "    bank_losses_assets = report_losses(df_RMBS_Final, df_loans_first_lien_domestic, df_treasury_and_others, df_other_loan, treasury_prices, RMBS_multiplier, df_asset)\n",
    "    \n",
    "    # Calculate the uninsured deposit/MM asset ratio\n",
    "    uninsured_deposit_mm_asset = calculate_uninsured_deposit_mm_asset(uninsured_deposit, bank_losses_assets)\n",
    "\n",
    "    # Calculate the insured deposit coverage ratio\n",
    "    insured_deposit_coverage = insured_deposit_coverage_ratio(insured_deposits, uninsured_deposit, bank_losses_assets)\n",
    "    \n",
    "    # Calculate the final statistics table\n",
    "    final_stats = final_statistic_table(bank_losses_assets, uninsured_deposit_mm_asset, insured_deposit_coverage)\n",
    "    \n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    ##Calculations for all GSIB banks################################################################################################################################\n",
    "    # Calculate the losses \n",
    "    bank_losses_assets_GSIB = report_losses(df_RMBS_GSIB, df_loans_first_lien_domestic_GSIB, df_treasury_and_others_GSIB, df_other_loan_GSIB, treasury_prices, RMBS_multiplier, df_asset_GSIB)\n",
    "    \n",
    "    # Calculate the uninsured deposit/MM asset ratio\n",
    "    uninsured_deposit_mm_asset_GSIB = calculate_uninsured_deposit_mm_asset(uninsured_deposit_GSIB, bank_losses_assets_GSIB)\n",
    "\n",
    "    # Calculate the insured deposit coverage ratio\n",
    "    insured_deposit_coverage_GSIB = insured_deposit_coverage_ratio(insured_deposits_GSIB, uninsured_deposit_GSIB, bank_losses_assets_GSIB)\n",
    "    \n",
    "    # Calculate the final statistics table\n",
    "    final_stats_GSIB = final_statistic_table(bank_losses_assets_GSIB, uninsured_deposit_mm_asset_GSIB, insured_deposit_coverage_GSIB, index_name = 'GSIB Banks')\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    ##Calculations for all Large non-GSIB banks################################################################################################################################\n",
    "    # Calculate the losses \n",
    "    bank_losses_assets_large_ex_GSIB = report_losses(df_RMBS_large_ex_GSIB, df_loans_first_lien_domestic_large_ex_GSIB, df_treasury_and_others_large_ex_GSIB, df_other_loan_large_ex_GSIB, treasury_prices, RMBS_multiplier, df_asset_large_ex_GSIB)\n",
    "    \n",
    "    # Calculate the uninsured deposit/MM asset ratio\n",
    "    uninsured_deposit_mm_asset_large_ex_GSIB = calculate_uninsured_deposit_mm_asset(uninsured_deposit_large_ex_GSIB, bank_losses_assets_large_ex_GSIB)\n",
    "\n",
    "    # Calculate the insured deposit coverage ratio\n",
    "    insured_deposit_coverage_large_ex_GSIB = insured_deposit_coverage_ratio(insured_deposits_large_ex_GSIB, uninsured_deposit_large_ex_GSIB, bank_losses_assets_large_ex_GSIB)\n",
    "    \n",
    "    # Calculate the final statistics table\n",
    "    final_stats_large_ex_GSIB = final_statistic_table(bank_losses_assets_large_ex_GSIB, uninsured_deposit_mm_asset_large_ex_GSIB, insured_deposit_coverage_large_ex_GSIB, index_name = 'Large Ex GSIB Banks')\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    ##Calculations for small banks################################################################################################################################\n",
    "    # Calculate the losses \n",
    "    bank_losses_assets_small = report_losses(df_RMBS_small, df_loans_first_lien_domestic_small, df_treasury_and_others_small, df_other_loan_small, treasury_prices, RMBS_multiplier, df_asset_small)\n",
    "    \n",
    "    # Calculate the uninsured deposit/MM asset ratio\n",
    "    uninsured_deposit_mm_asset_small = calculate_uninsured_deposit_mm_asset(uninsured_deposit_small, bank_losses_assets_small)\n",
    "\n",
    "    # Calculate the insured deposit coverage ratio\n",
    "    insured_deposit_coverage_small = insured_deposit_coverage_ratio(insured_deposits_small, uninsured_deposit_small, bank_losses_assets_small)\n",
    "    \n",
    "    # Calculate the final statistics table\n",
    "    final_stats_small = final_statistic_table(bank_losses_assets_small, uninsured_deposit_mm_asset_small, insured_deposit_coverage_small, index_name = 'Small Banks')\n",
    "    ##################################################################################################################################################################\n",
    "\n",
    "    table_1 = pd.concat([final_stats, final_stats_small, final_stats_large_ex_GSIB, final_stats_GSIB], axis=1)\n",
    "\n",
    "    # Sets format for printing to LaTeX\n",
    "    float_format_func = lambda x: '{:.1f}'.format(x)\n",
    "    latex_table_string = table_1.to_latex(float_format=float_format_func)\n",
    "    path = OUTPUT_DIR / f'Table1.tex'\n",
    "    with open(path, \"w\") as text_file:\n",
    "        text_file.write(latex_table_string)\n",
    "\n",
    "    print(table_1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
